{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from Predictions.RunSVM_copy4matrix import *\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.cluster.vq import whiten\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from robust.pcp import pcp\n",
    "from robust.rpca import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Train corpus:\n",
      "Building Corpus...\n",
      "0/4150 advance\n",
      "500/4150 advance\n",
      "1000/4150 advance\n",
      "1500/4150 advance\n",
      "2000/4150 advance\n",
      "2500/4150 advance\n",
      "3000/4150 advance\n",
      "3500/4150 advance\n",
      "4000/4150 advance\n",
      "Corpus Ready!!\n",
      "Loading Valid corpus:\n",
      "Building Corpus...\n",
      "0/903 advance\n",
      "500/903 advance\n",
      "Corpus Ready!!\n",
      "Building Train GloVeToCropus:\n",
      "Building Corpus Vectors...\n",
      "0/4150 advance\n",
      "500/4150 advance\n",
      "1000/4150 advance\n",
      "1500/4150 advance\n",
      "2000/4150 advance\n",
      "2500/4150 advance\n",
      "3000/4150 advance\n",
      "3500/4150 advance\n",
      "4000/4150 advance\n",
      "Corpus Vectors Ready!!\n",
      "Building Valid GloVeToCropus:\n",
      "Building Corpus Vectors...\n",
      "0/903 advance\n",
      "500/903 advance\n",
      "Corpus Vectors Ready!!\n"
     ]
    }
   ],
   "source": [
    "VocabSizeChecker()\n",
    "#train_features, valid_features = buildFeatures()\n",
    "\n",
    "data_dir = 'Data'\n",
    "min_val = 100\n",
    "file_type = 'gloves'\n",
    "vocab_size = 10000\n",
    "\n",
    "train_features, valid_features = buildFeatures()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building targets...\n",
      "Target balance on train:\n",
      "Topic: Educación; Percet Ones: 11.0%\n",
      "Topic: Campo; Percet Ones: 4.0%\n",
      "Topic: Sistema Financiero; Percet Ones: 1.0%\n",
      "Topic: Electoral; Percet Ones: 5.0%\n",
      "Topic: Derechos Humanos; Percet Ones: 9.0%\n",
      "Topic: Medio Ambiente; Percet Ones: 8.0%\n",
      "Topic: Laboral; Percet Ones: 8.0%\n"
     ]
    }
   ],
   "source": [
    "topics, train_target, valid_target = buildTargets()\n",
    "train_features, valid_features, train_target, valid_target = dropMissing(train_features, valid_features, train_target, valid_target)\n",
    "printTargetBalance(topics, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Educación',\n",
       " 'Campo',\n",
       " 'Sistema Financiero',\n",
       " 'Electoral',\n",
       " 'Derechos Humanos',\n",
       " 'Medio Ambiente',\n",
       " 'Laboral']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numpy.savetxt(\"dense_data/train_features.csv\", train_features, delimiter=\",\")\n",
    "numpy.savetxt(\"dense_data/valid_features.csv\", valid_features, delimiter=\",\")\n",
    "numpy.savetxt(\"dense_data/train_target.csv\", np.array(train_target) , delimiter=\",\")\n",
    "numpy.savetxt(\"dense_data/valid_target.csv\", np.array(valid_target) , delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denoising of dense matrix:\n",
    "    1. Random projection \n",
    "    2. PCA\n",
    "        - w/ whitening \n",
    "    3. Robust PCA\n",
    "        -Split into Low-Rank and Sparse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use 16 Low Rank features and 1 Sparse feature."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python3]",
   "language": "python",
   "name": "conda-env-python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
